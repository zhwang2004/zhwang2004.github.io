<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ziheng Wang</title>

    <meta name="author" content="Ziheng Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <meta name="google-site-verification" content="WIbr-i_iC6L_xOi7AzP1WUYzB4E2nbNTrwwgPQD1Daw" />
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Header / Intro -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align:center;">
                  Ziheng Wang
                </p>
    <p>
    I am currently an undergraduate advised by
    <a href="https://scholar.google.com/citations?user=roGixUIAAAAJ&hl=en" target="_blank" rel="noopener">Xu Cheng</a> (NUIST).
    I will soon begin my Ph.D. at the
      <a href="http://www.patternrecognition.asia/" target="_blank" rel="noopener">PCA Lab</a>
      , co-advised by
    <a href="https://scholar.google.com/citations?user=6CIDtZQAAAAJ&hl=en" target="_blank" rel="noopener">Jian Yang</a> (NKU)
    and
    <a href="https://gsmis.njust.edu.cn/open/TutorInfo.aspx?dsbh=RmWOl5Z6qPvrztHQCPe!zQ==&yxsh=z70ppxVSQAs=&zydm=SwsWR9zpmmw=" target="_blank" rel="noopener">Jianjun Qian</a> (NJUST).
    My research focuses on building reliable visual intelligence systems, with interests spanning deep learning, computer vision, pattern recognition, and computer graphics.
    I am particularly passionate about connecting <em>perception</em> with <em>real-world applications</em>, and always open to academic collaboration.
    Feel free to reach out at <a href="mailto:zhwang@nuist.edu.cn">zhwang@nuist.edu.cn</a>.
</p>


                <p style="text-align:center">
                  <a href="mailto:zhwang@nuist.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/ZihengWang-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=PAOguIoAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Nickory">GitHub</a> &nbsp;/&nbsp;
                  <a href="#">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/ZihengWang.jpg"><img style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;" alt="profile photo" src="images/ZihengWang.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- Research -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                   My interests lie in intelligent perception, human-centered sensing, and reliable machine learning under real-world constraints such as noise and data imbalance. I enjoy transforming ideas into practical systems â€” from algorithms and datasets to deployable prototypes across software and embedded platforms.
                </p>

              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/research/fscfnet.jpg" alt="FSCFNet paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://scholar.google.com/scholar?q=Think%20Locally%2C%20Act%20Globally%3A%20A%20Frequency-Spatial%20Fusion%20Network%20for%20Infrared%20Small%20Target%20Detection" target="_blank" rel="noopener">
        <span class="papertitle">Think Locally, Act Globally: A Frequencyâ€‘Spatial Fusion Network for Infrared Small Target Detection</span>
      </a>
      <br>
      Weijie Xu, Zhenglong Ding, <strong>Ziheng Wang</strong>, Zhiqing Cui, Yifan Hu, Feng Jiang
      <br>
      <em>IEEE Transactions on Geoscience and Remote Sensing</em>, 2025/9/22 &nbsp;|&nbsp; Publisher: IEEE
      <p></p>
      <p style="margin-top:8px;">We introduce <strong>FSCFNet</strong> on YOLOv10n with a novel <em>frequencyâ€‘spatial convolution</em> (FSConv) using Haar wavelets. Highâ€‘frequency branches enhance tinyâ€‘target details while lowâ€‘frequency branches keep global context. An asymmetric crossâ€‘domain attention (ACA) module sharpens the typical Gaussianâ€‘like local patterns of IR small targets; customized multiâ€‘scale receptive designs improve speedâ€‘accuracy tradeâ€‘offs.</p>
    </td>
  </tr>
  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/research/appboost1.jpg" alt="APPBoost paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
      <img src="images/research/appboost.jpg" alt="APPBoost paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://scholar.google.com/scholar?q=APPBoost%3A%20an%20adaptive%20parameter%20pair%20boosting%20algorithm%20for%20enhanced%20robustness%20against%20noise%20and%20imbalance" target="_blank" rel="noopener">
        <span class="papertitle">APPBoost: an adaptive parameter pair boosting algorithm for enhanced robustness against noise and imbalance</span>
      </a>
      <br>
      <strong>Ziheng Wang</strong>, Zixuan Shao, Baowei Wang, Xu Cheng
      <br>
      <em>The Journal of Supercomputing</em>, 2025/3/9 &nbsp;|&nbsp; Volume 81, Issue 4, Pages 594 &nbsp;|&nbsp; Publisher: Springer US
      <p></p>
      <p style="margin-top:8px;">We propose <strong>APPBoost</strong>, which introduces a parameter pair within a new loss and weightâ€‘update scheme to downâ€‘weight noisy/mislabeled samples while preserving hard informative cases. The method bounds training error, relates to Forward Stagewise Additive Modeling, and empirically improves generalization under noise/imbalance.</p>
    </td>
  </tr>
  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/research/awab_svm.jpg" alt="AWABoost-SVM paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://scholar.google.com/scholar?q=An%20adaptive%20weighted%20boosting%20framework%20for%20enhanced%20cardiovascular%20disease%20diagnosis" target="_blank" rel="noopener">
        <span class="papertitle">An adaptive weighted boosting framework for enhanced cardiovascular disease diagnosis</span>
      </a>
      <br>
      <strong>Ziheng Wang</strong>, Zixuan Shao, Baowei Wang, Xu Cheng
      <br>
      <em>Biomedical Signal Processing and Control</em>, 2025/5/1 &nbsp;|&nbsp; Volume 103, Pages 107447 &nbsp;|&nbsp; Publisher: Elsevier
      <p></p>
      <p style="margin-top:8px;">We propose <strong>AWABoostâ€‘SVM</strong> with two key parameters (Î¸, C): Î¸ dynamically tunes the weightâ€‘update strength for harder samples; C regularizes the SVM to balance complexity and error. Bayesian optimization selects Î¸ and C via expected improvement, yielding robust performance on highâ€‘dimensional/noisy CVD data.</p>
    </td>
  </tr>
</tbody></table>

          <!-- Projects -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Projects</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/projects/rayvita.jpg" alt="RayVita" width="160" style="border-radius:8px;object-fit:cover;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://github.com/Nickory/RayVita"><span class="papertitle">RayVita: AIâ€‘Powered Digital Health Twin System</span></a>
                <br>
                <em>rPPG, HR/HRV, microâ€‘expression, AI tips, Android + Web</em>
                <p>Endâ€‘toâ€‘end healthâ€‘tech ecosystem: remote vitals from camera, AI insights and coaching, and a modular UI.</p>
              </td>
            </tr>
          </tbody></table>

<!-- News -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:24px;"><tbody>
  <tr>
    <td style="padding:16px;width:100%;vertical-align:middle">
      <h2>News</h2>
      <ul>

        <li><strong>Oct 2025</strong> â€” Awarded the <em>National Scholarship for Undergraduates</em> (Top 2%) ðŸŽ‰ðŸŽŠðŸŽŠ</li>
        <li><strong>Sep 2025</strong> â€” Our paper was accepted by <em>IEEE Transactions on Geoscience and Remote Sensing (TGRS, CCF-B)</em> ðŸ¥³ðŸ¥³âœ¨</li>
        <li><strong>Aug 2025</strong> â€” Joined the <strong>PCA Lab</strong> as an incoming Ph.D. student ðŸŽ“ </li>
        <li><strong>Jul 2025</strong> â€” Conducted a summer research internship at <strong>Zhejiang University</strong> </li>
        <li><strong>Mar 2025</strong> â€” Our <em>APPBoost-based invention patent</em> was officially granted ðŸŽ‰ðŸŽŠðŸŽŠ</li>
        <li><strong>Feb 2025</strong> â€” Our paper was accepted by <em>Journal of Supercomputing (CCF-C)</em> ðŸ¥³ðŸ¥³âœ¨</li>
        <li><strong>May 2024</strong> â€” Led a project funded by the <em>National Innovation & Entrepreneurship Training Program</em> (Top 5%) ðŸŽ‰ðŸŽŠðŸŽŠ</li>
        <li><strong>Oct 2023</strong> â€” Won the <em>National Second Prize</em> in the <em>China Undergraduate Mathematical Contest in Modeling</em> (Top 2%) ðŸŽ‰ðŸŽŠðŸŽŠ</li>
        <li><strong>May 2023</strong> â€” Received the <em>First Prize</em> in the <em>Jiangsu Advanced Mathematics Competition</em> (Top 5%) ðŸŽ‰ðŸŽŠðŸŽŠ</li>

      </ul>
    </td>
  </tr>
</tbody></table>


          <!-- Footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:32px auto 16px;"><tbody>
            <tr>
              <td style="text-align:center;padding:8px;opacity:0.7;font-size:0.9em;">
                Â© Ziheng Wang. Built from a simplified academic homepage template. Last updated: <script>document.write(new Date().toISOString().slice(0,10));</script>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </tbody></table>
  </body>
</html>
