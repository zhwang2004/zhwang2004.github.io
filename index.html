<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ziheng Wang</title>

    <meta name="author" content="Ziheng Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Homepage of Ziheng Wang, AI researcher and incoming Ph.D. student at PCA Lab (NJU ST). Research in deep learning, computer vision, pattern recognition and robust machine learning.">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <meta name="google-site-verification" content="WIbr-i_iC6L_xOi7AzP1WUYzB4E2nbNTrwwgPQD1Daw" />
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Header / Intro -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align:center;">
                  Ziheng Wang
                </p>
    <p>
    I am currently an undergraduate advised by
    <a href="https://scholar.google.com/citations?user=roGixUIAAAAJ&hl=en" target="_blank" rel="noopener">Xu Cheng</a> (NUIST).
    I will soon begin my Ph.D. at the
      <a href="http://www.patternrecognition.asia/" target="_blank" rel="noopener">PCA Lab</a>
      , co-advised by
    <a href="https://scholar.google.com/citations?user=6CIDtZQAAAAJ&hl=en" target="_blank" rel="noopener">Jian Yang</a> (NKU)
    and
    <a href="https://gsmis.njust.edu.cn/open/TutorInfo.aspx?dsbh=RmWOl5Z6qPvrztHQCPe!zQ==&yxsh=z70ppxVSQAs=&zydm=SwsWR9zpmmw=" target="_blank" rel="noopener">Jianjun Qian</a> (NJUST).
    My research focuses on building reliable visual intelligence systems, with interests spanning deep learning, computer vision, pattern recognition, and computer graphics.
    I am particularly passionate about connecting <em>perception</em> with <em>real-world applications</em>, and always open to academic collaboration.
    Feel free to reach out at <a href="mailto:zhwang@nuist.edu.cn">zhwang@nuist.edu.cn</a>.
</p>


                <p style="text-align:center">
                  <a href="mailto:zhwang@nuist.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/ZihengWang-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=PAOguIoAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Nickory">GitHub</a> &nbsp;/&nbsp;
                  <a href="#">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/ZihengWang.jpg"><img style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;" alt="profile photo" src="images/ZihengWang.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- Research -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                   My interests lie in intelligent perception, human-centered sensing, and reliable machine learning under real-world constraints such as noise and data imbalance. I enjoy transforming ideas into practical systems â€” from algorithms and datasets to deployable prototypes across software and embedded platforms.
                </p>

              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/research/fscfnet.jpg" alt="FSCFNet paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://scholar.google.com/scholar?q=Think%20Locally%2C%20Act%20Globally%3A%20A%20Frequency-Spatial%20Fusion%20Network%20for%20Infrared%20Small%20Target%20Detection" target="_blank" rel="noopener">
        <span class="papertitle">Think Locally, Act Globally: A Frequencyâ€‘Spatial Fusion Network for Infrared Small Target Detection</span>
      </a>
      <br>
      Weijie Xu, Zhenglong Ding, <strong>Ziheng Wang</strong>, Zhiqing Cui, Yifan Hu, Feng Jiang
      <br>
      <em>IEEE Transactions on Geoscience and Remote Sensing</em>, 2025 &nbsp;|&nbsp; Publisher: IEEE
      <p></p>
      <p style="margin-top:8px;">We introduce <strong>FSCFNet</strong> on YOLOv10n with a novel <em>frequencyâ€‘spatial convolution</em> (FSConv) using Haar wavelets. Highâ€‘frequency branches enhance tinyâ€‘target details while lowâ€‘frequency branches keep global context. An asymmetric crossâ€‘domain attention (ACA) module sharpens the typical Gaussianâ€‘like local patterns of IR small targets; customized multiâ€‘scale receptive designs improve speedâ€‘accuracy tradeâ€‘offs.</p>
    </td>
  </tr>
  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/research/appboost1.jpg" alt="APPBoost paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
      <img src="images/research/appboost.jpg" alt="APPBoost paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://scholar.google.com/scholar?q=APPBoost%3A%20an%20adaptive%20parameter%20pair%20boosting%20algorithm%20for%20enhanced%20robustness%20against%20noise%20and%20imbalance" target="_blank" rel="noopener">
        <span class="papertitle">APPBoost: an adaptive parameter pair boosting algorithm for enhanced robustness against noise and imbalance</span>
      </a>
      <br>
      <strong>Ziheng Wang</strong>, Zixuan Shao, Baowei Wang, Xu Cheng
      <br>
      <em>The Journal of Supercomputing</em>, 2025 &nbsp;|&nbsp; Volume 81, Issue 4, Pages 594 &nbsp;|&nbsp; Publisher: Springer US
      <p></p>
      <p style="margin-top:8px;">We propose <strong>APPBoost</strong>, which introduces a parameter pair within a new loss and weightâ€‘update scheme to downâ€‘weight noisy/mislabeled samples while preserving hard informative cases. The method bounds training error, relates to Forward Stagewise Additive Modeling, and empirically improves generalization under noise/imbalance.</p>
    </td>
  </tr>
  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <img src="images/research/awab_svm.jpg" alt="AWABoost-SVM paper figure" width="160" style="border-radius:8px;object-fit:cover;" onerror="this.onerror=null;this.src='images/placeholder.jpg';">
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://scholar.google.com/scholar?q=An%20adaptive%20weighted%20boosting%20framework%20for%20enhanced%20cardiovascular%20disease%20diagnosis" target="_blank" rel="noopener">
        <span class="papertitle">An adaptive weighted boosting framework for enhanced cardiovascular disease diagnosis</span>
      </a>
      <br>
      <strong>Ziheng Wang</strong>, Zixuan Shao, Baowei Wang, Xu Cheng
      <br>
      <em>Biomedical Signal Processing and Control</em>, 2025 &nbsp;|&nbsp; Volume 103, Pages 107447 &nbsp;|&nbsp; Publisher: Elsevier
      <p></p>
      <p style="margin-top:8px;">We propose <strong>AWABoostâ€‘SVM</strong> with two key parameters: one dynamically tunes the weightâ€‘update strength for harder samples; the other regularizes the SVM to balance complexity and error.</p>
    </td>
  </tr>
</tbody></table>

          <!-- Projects -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Projects</h2>
              </td>
            </tr>
          </tbody></table>

          <style>
.hover-video-container {
  position: relative;
  width: 160px;
  height: 90px; /* ä½ å¯ä»¥æ ¹æ®è§†é¢‘æ¯”ä¾‹è°ƒæ•´ï¼Œæ¯”å¦‚ 160x160 æ–¹å½¢ä¹Ÿè¡Œ */
  border-radius: 8px;
  overflow: hidden;
}

.hover-video-container img,
.hover-video-container video {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.hover-video-container video {
  display: none;
}
.hover-video-container:hover img {
  display: none;
}
.hover-video-container:hover video {
  display: block;
}
</style>

<table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="hover-video-container">
        <img src="images/projects/rayvita.jpg" alt="RayVita">
        <video muted loop
          onmouseover="this.play();"
          onmouseout="this.pause(); this.currentTime = 0;">
          <source src="http://47.96.237.130/assets/vedio/MAIN%20COMP_20250602_23182440_20250602_23243208_20250602_23255819.mp4" type="video/mp4">
        </video>
      </div>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://github.com/Nickory/RayVita"><span class="papertitle">RayVita: AI-Powered Digital Health Twin System</span></a>
      <br>
      <em>rPPG, HR/HRV, micro-expression, AI tips, Android + Web</em>
      <p>End-to-end health-tech ecosystem: remote vitals from camera, AI insights and coaching, and a modular UI.</p>
      <p>
        <a href="data/RayVita.pdf" target="_blank">PDF Introduction</a>
      </p>
    </td>
  </tr>
</tbody></table>

<!-- News -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:24px;"><tbody>
  <tr>
    <td style="padding:16px;width:100%;vertical-align:middle">
      <h2>News</h2>
      <ul>

        <!-- NEW with photo -->
        <li style="display:flex;align-items:center;gap:12px;margin-bottom:8px;">
          <img src="images/award.jpg" alt="award photo" 
               style="width:120px;height:100x;border-radius:6px;object-fit:cover;">
          <span>
            <strong>Nov 2025</strong> â€” Received awards from <strong>Prof. Haishan Chen</strong>, 
            President of Nanjing University of Information Science & Technology, and 
            <strong>Prof. Veronica Campbell</strong>, President of South East Technological University (Ireland) ğŸ…âœ¨
          </span>
        </li>

        <li><strong>Nov 2025</strong> â€” Honored as the universityâ€™s <em>â€œThree-Good Student Pacesetterâ€</em> (Top &lt;2%) ğŸ‰ğŸ–ï¸</li>
        <li><strong>Oct 2025</strong> â€” Awarded the <em>National Scholarship for Undergraduates</em> (Top 2%) ğŸ‰ğŸŠğŸŠ</li>
        <li><strong>Sep 2025</strong> â€” Our paper was accepted by <em>IEEE Transactions on Geoscience and Remote Sensing (TGRS, CCF-B)</em> ğŸ¥³ğŸ¥³âœ¨</li>
        <li><strong>Aug 2025</strong> â€” Joined the <strong>PCA Lab</strong> as an incoming Ph.D. student ğŸ“ </li>
        <li><strong>Jul 2025</strong> â€” Conducted a summer research internship at <strong>Zhejiang University</strong> </li>
        <li><strong>Mar 2025</strong> â€” Our <em>APPBoost-based invention patent</em> was officially granted ğŸ‰ğŸŠğŸŠ</li>
        <li><strong>Feb 2025</strong> â€” Our paper was accepted by <em>Journal of Supercomputing (CCF-C)</em> ğŸ¥³ğŸ¥³âœ¨</li>
        <li><strong>May 2024</strong> â€” Led a project funded by the <em>National Innovation & Entrepreneurship Training Program</em> (Top 5%) ğŸ‰ğŸŠğŸŠ</li>
        <li><strong>Oct 2023</strong> â€” Won the <em>National Second Prize</em> in the <em>China Undergraduate Mathematical Contest in Modeling</em> (Top 2%) ğŸ‰ğŸŠğŸŠ</li>
        <li><strong>May 2023</strong> â€” Received the <em>First Prize</em> in the <em>Jiangsu Advanced Mathematics Competition</em> (Top 5%) ğŸ‰ğŸŠğŸŠ</li>

      </ul>
    </td>
  </tr>
</tbody></table>


<a href="https://mapmyvisitors.com/web/1c0jk"  title="Visit tracker"><img src="https://mapmyvisitors.com/map.png?d=0Jb4bEkqtvpa8KsUuZr3EJdELdPBUOahUrShHJ9yzP4&cl=ffffff" /></a>
          <!-- Footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:32px auto 16px;"><tbody>
            <tr>
              <td style="text-align:center;padding:8px;opacity:0.7;font-size:0.9em;">
                Â© Ziheng Wang. Built from a simplified academic homepage template. Last updated: <script>document.write(new Date().toISOString().slice(0,10));</script>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </tbody></table>
  </body>
</html>
